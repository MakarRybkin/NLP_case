{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13091854,"sourceType":"datasetVersion","datasetId":8209802}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Решение вступительного на смену ML в Сириусе сенятбрь 2025","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers torch pandas accelerate tqdm transformers_stream_generator","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom tqdm.auto import tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def set_seed(seed = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DATA_PATH = '/kaggle/input/t-contest-nlp/'\ndata = pd.read_csv(DATA_PATH + 'train.csv')\ndata","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"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\") ","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categories = [\n    'бытовая техника',\n    'обувь',\n    'одежда',\n    'посуда',\n    'текстиль',\n    'товары для детей',\n    'украшения и аксессуары',\n    'электроника',\n    'нет товара'\n]\n\nmodel_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\n\ndata['label'] = ''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def classify_review(review_text):\n    prompt = f\"\"\"\nКлассифицируй следующий отзыв по одной из категорий: {', '.join(categories)}.\nЕсли отзыв нельзя отнести к одной из категорий с высокой вероятностью, выбери 'нет товара'.\nОтветь только одним словом — названием категории, без лишних символов.\n\nОтзыв: \"{review_text}\"\nКатегория:\n    \"\"\".strip()\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=30,       \n        do_sample=False,         \n        temperature=0.0,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    print(response)\n    if \"Категория:\" in response:\n        response = response.split(\"Категория:\")[-1]\n    response = response.strip().lower().replace(\"-\", \" \")\n    for category in categories:\n        if category.lower() in response:\n            return category\n    return \"нет товара\"\n\n\nfor index, row in data.iterrows():\n    data.loc[index, 'label'] = classify_review(row['text'])\n    print(f\"Обработан отзыв {index+1}/{len(data)}. Метка: {data.loc[index, 'label']}\")\n\ndata.to_csv('train_labeled.csv', index=False)","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Перезапускаю среду из-за Out of memory, загружаю полученные размеченные данные ","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/t-contest-nlp/train_labeled.csv')\ntrain_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q peft datasets accelerate bitsandbytes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset\n\nlabel2id = {c: i for i, c in enumerate(categories)}\nid2label = {i: c for c, i in label2id.items()}\ntrain_df['label'] = train_df['label'].map(label2id)\n\ntest_df = pd.read_csv('/kaggle/input/t-contest-nlp/test.csv')\n\ntrain_ds = Dataset.from_pandas(train_df)\ntest_ds = Dataset.from_pandas(test_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntokenizer.pad_token = tokenizer.eos_token\nmodel.config.pad_token_id = tokenizer.pad_token_id\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], truncation=True, padding=True, max_length=256)\n    \ntrain_ds = train_ds.map(tokenize, batched=True)\ntest_ds = test_ds.map(tokenize, batched=True)\n\ntrain_ds = train_ds.rename_column(\"label\", \"labels\")\n\ntrain_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\ntest_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nfrom peft import LoraConfig, get_peft_model\n\nbase_model = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=len(categories),\n    id2label=id2label,\n    label2id=label2id,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\n\nconfig = LoraConfig(\n    r=16,\n    lora_alpha=16, \n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"SEQ_CLS\"\n)\n\nmodel = get_peft_model(base_model, config)\nmodel.print_trainable_parameters()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=1,\n    learning_rate=1e-4,\n    num_train_epochs=1,\n    logging_steps=100,\n    save_strategy=\"no\",\n    report_to=\"none\",\n    seed=42,\n    bf16=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    tokenizer=tokenizer,\n)\n\ntrainer.train()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Снова Out of memory, сохраняю веса модели ","metadata":{}},{"cell_type":"code","source":"output_dir = \"./my_finetuned_model\"\ntrainer.save_model(output_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport zipfile\n\n# Replace 'path/to/your/folder' with the actual path\nfolder_to_zip = './my_finetuned_model' \noutput_zip_file = './my_finetuned_model.zip'\n\n# Check if the folder exists\nif not os.path.isdir(folder_to_zip):\n    print(f\"Directory '{folder_to_zip}' does not exist.\")\nelse:\n    # Create the zip file\n    with zipfile.ZipFile(output_zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        # Walk through the directory and add files to the zip\n        for root, dirs, files in os.walk(folder_to_zip):\n            for file in files:\n                # Create a relative path to keep the directory structure inside the zip\n                relative_path = os.path.relpath(os.path.join(root, file), folder_to_zip)\n                zipf.write(os.path.join(root, file), relative_path)\n    print(f\"Successfully created '{output_zip_file}'. You can now download it.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n\nmodel_path = \"/kaggle/input/t-contest-nlp/my_finetuned_model\"\n\nloaded_tokenizer = AutoTokenizer.from_pretrained(model_path)\n\nloaded_model = AutoModelForSequenceClassification.from_pretrained(\n    model_path,\n    num_labels=len(categories),\n    id2label=id2label,\n    label2id=label2id\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n)\n\nnew_trainer = Trainer(\n    model=loaded_model,\n    args=training_args,\n    tokenizer=loaded_tokenizer\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-17T20:40:24.186Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = trainer.predict(test_dataset=test_ds)\n\nlogits = predictions.predictions\n\npredicted_ids = torch.argmax(torch.tensor(logits), axis=-1).cpu().numpy()\n\npredicted_labels = [id2label[id] for id in predicted_ids]\n\nsubmission_df = pd.DataFrame({'id': test_df['id'], 'label': predicted_labels})\n\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(\"Файл submission.csv успешно создан.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}